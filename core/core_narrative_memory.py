# core/core_narrative_memory.py (V2 - Embeddings Powered)
import logging
import uuid
from typing import Dict, Any, List, Optional
from datetime import datetime
import numpy as np
import pandas as pd

# Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø®Ø¯Ù…Ø© LLM Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…ØªØ¬Ù‡Ø§Øª
import google.generativeai as genai
from google.generativeai.types import EmbedContentConfig, TaskType

logger = logging.getLogger("CoreNarrativeMemory")

class MemoryEntry:
    # ... (ÙŠÙ…ÙƒÙ† ØªØ¨Ø³ÙŠØ·Ù‡Ø§ Ø£Ùˆ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù‚Ø§Ù…ÙˆØ³ Ù…Ø¨Ø§Ø´Ø±Ø©)
    def __init__(self, entry_type: str, content: str, metadata: Dict[str, Any]):
        self.id = str(uuid.uuid4())
        self.type = entry_type
        self.content = content
        self.metadata = metadata or {}
        self.timestamp = datetime.now()
        # Ø³ÙŠØªÙ… Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…ØªØ¬Ù‡ Ù„Ø§Ø­Ù‚Ù‹Ø§

class CoreNarrativeMemory:
    """
    Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ø³Ø±Ø¯ÙŠØ© Ø§Ù„Ù…Ø±ÙƒØ²ÙŠØ© (V2).
    ØªØ³ØªØ®Ø¯Ù… Gemini Embeddings Ù„ØªÙˆÙÙŠØ± Ø³ÙŠØ§Ù‚ Ø°ÙƒÙŠ ÙˆØ·ÙˆÙŠÙ„ Ø§Ù„Ù…Ø¯Ù‰.
    """
    def __init__(self):
        self.embedding_model = 'models/embedding-001'
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… Pandas DataFrame ÙƒÙ…Ø­Ø§ÙƒØ§Ø© Ù„Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ù…ØªØ¬Ù‡Ø© (Vector DB)
        self.memory_df = pd.DataFrame(columns=['id', 'type', 'content', 'metadata', 'timestamp', 'embedding'])
        logger.info("âœ… Core Narrative Memory (V2) initialized with in-memory DataFrame.")

    def _generate_embedding(self, text: str, task_type: TaskType) -> List[float]:
        """
        ØªÙˆÙ„Ø¯ Ù…ØªØ¬Ù‡Ù‹Ø§ Ø¯Ù„Ø§Ù„ÙŠÙ‹Ø§ Ù„Ù„Ù†Øµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Gemini API.
        """
        try:
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… task_type Ø§Ù„ØµØ­ÙŠØ­ Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£ÙØ¶Ù„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
            response = genai.embed_content(
                model=self.embedding_model,
                content=text,
                task_type=task_type
            )
            return response['embedding']
        except Exception as e:
            logger.error(f"Failed to generate embedding: {e}")
            return []

    def add_entry(self, entry_type: str, content: str, metadata: Optional[Dict[str, Any]] = None):
        """
        ØªØ¶ÙŠÙ Ø¥Ø¯Ø®Ø§Ù„Ø§Ù‹ Ø¬Ø¯ÙŠØ¯Ù‹Ø§ Ø¥Ù„Ù‰ Ø§Ù„Ø°Ø§ÙƒØ±Ø©ØŒ Ù…Ø¹ ØªÙˆÙ„ÙŠØ¯ Ù…ØªØ¬Ù‡ Ø¯Ù„Ø§Ù„ÙŠ Ù„Ù‡.
        """
        if not content:
            return

        entry = MemoryEntry(entry_type, content, metadata)
        # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…ØªØ¬Ù‡ ÙƒÙ€ 'document' Ù„Ø£Ù†Ù‡ Ø³ÙŠØªÙ… Ø§Ù„Ø¨Ø­Ø« ÙÙŠÙ‡ Ù„Ø§Ø­Ù‚Ù‹Ø§
        embedding = self._generate_embedding(content, TaskType.RETRIEVAL_DOCUMENT)
        
        if not embedding:
            logger.warning(f"Could not generate embedding for entry. Skipping add.")
            return

        new_entry_df = pd.DataFrame([{
            'id': entry.id,
            'type': entry.type,
            'content': entry.content,
            'metadata': entry.metadata,
            'timestamp': entry.timestamp,
            'embedding': embedding
        }])
        
        self.memory_df = pd.concat([self.memory_df, new_entry_df], ignore_index=True)
        logger.info(f"ðŸ§  New memory entry added: [ID: {entry.id}, Type: {entry.type}]")

    def query(self, query_text: str, top_k: int = 3, entry_type_filter: Optional[str] = None) -> List[Dict[str, Any]]:
        """
        ØªØ³ØªØ¹Ù„Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ Ù„Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„Ø§Øª Ø§Ù„Ø£ÙƒØ«Ø± ØµÙ„Ø©.
        """
        if self.memory_df.empty:
            return []

        # ØªÙˆÙ„ÙŠØ¯ Ù…ØªØ¬Ù‡ Ù„Ù„Ø³Ø¤Ø§Ù„
        query_embedding = self._generate_embedding(query_text, TaskType.RETRIEVAL_QUERY)
        if not query_embedding:
            return []

        # ØªØµÙÙŠØ© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ Ø¥Ø°Ø§ ØªÙ… ØªØ­Ø¯ÙŠØ¯Ù‡
        target_df = self.memory_df
        if entry_type_filter:
            target_df = self.memory_df[self.memory_df['type'] == entry_type_filter]

        if target_df.empty:
            return []

        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¶Ø±Ø¨ Ø§Ù„Ù†Ù‚Ø·ÙŠ (Dot Product) Ù„Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„ØªØ´Ø§Ø¨Ù‡
        dot_products = np.dot(np.stack(target_df['embedding']), query_embedding)
        
        # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø¤Ø´Ø±Ø§Øª Ø£ÙØ¶Ù„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        # Ù†Ø³ØªØ®Ø¯Ù… argpartition Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£ÙØ¶Ù„ k Ø¨ÙƒÙØ§Ø¡Ø©
        # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø¹Ø¯Ø¯ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø£Ù‚Ù„ Ù…Ù† kØŒ Ù†Ø£Ø®Ø° ÙƒÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        num_results = min(top_k, len(dot_products))
        indices = np.argpartition(dot_products, -num_results)[-num_results:]
        
        # ØªØ±ØªÙŠØ¨ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø­Ø³Ø¨ Ø¯Ø±Ø¬Ø© Ø§Ù„ØªØ´Ø§Ø¨Ù‡
        results_df = target_df.iloc[indices]
        results_df['similarity'] = dot_products[indices]
        results_df = results_df.sort_values(by='similarity', ascending=False)
        
        return results_df.to_dict('records')

    def get_full_chronology(self) -> List[Dict[str, Any]]:
        """ØªØ±Ø¬Ø¹ ÙƒÙ„ Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„Ø§Øª Ù…Ø±ØªØ¨Ø© Ø²Ù…Ù†ÙŠØ§Ù‹."""
        return self.memory_df.sort_values(by='timestamp').to_dict('records')
        
    def clear(self):
        """ØªÙ…Ø³Ø­ Ø§Ù„Ø°Ø§ÙƒØ±Ø© (Ù„Ø¨Ø¯Ø¡ Ù…Ø´Ø±ÙˆØ¹ Ø¬Ø¯ÙŠØ¯)."""
        self.memory_df = pd.DataFrame(columns=['id', 'type', 'content', 'metadata', 'timestamp', 'embedding'])
        logger.info("Core Narrative Memory has been cleared.")

# Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø«ÙŠÙ„ ÙˆØ­ÙŠØ¯ Ù„Ù„Ø°Ø§ÙƒØ±Ø©
narrative_memory = CoreNarrativeMemory()
