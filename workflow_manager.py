# core/workflow_manager.py (Ø§Ù„Ø¥ØµØ¯Ø§Ø± Ø§Ù„Ù…Ø­Ø¯Ø« Ø¨Ø§Ù„ÙƒØ§Ù…Ù„)
import logging
import json
import asyncio
from typing import Dict, Any, List, Optional, Callable

# Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ù…Ù†Ø³Ù‚ Ø§Ù„Ù…Ø­Ø¯Ø« ÙˆØ§Ù„Ù…Ø­Ø±ÙƒØ§Øª
from core.apollo_orchestrator import apollo
from ingestion.ingestion_engine import InputType, ingestion_engine
from advanced_context_engine import AdvancedContextEngine # Ù„Ø§Ø³ØªØ®Ù„Ø§Øµ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ø£ÙˆÙ„ÙŠØ©

# --- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ³Ø¬ÙŠÙ„ ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - [WorkflowManager] - %(levelname)s - %(message)s')
logger = logging.getLogger("WorkflowManager")

class WorkflowManager:
    """
    ÙŠØ¯ÙŠØ± Ø®Ø·ÙˆØ· Ø§Ù„Ø¥Ù†ØªØ§Ø¬ Ø§Ù„Ø¥Ø¨Ø¯Ø§Ø¹ÙŠØ© Ø§Ù„Ù…Ø¹Ù‚Ø¯Ø© (Pipelines)ØŒ ÙˆÙŠÙ†Ø³Ù‚ Ø³Ù„Ø³Ù„Ø© Ù…Ù† Ø§Ù„Ù…Ù‡Ø§Ù…
    Ø§Ù„ØªÙŠ ÙŠÙ†ÙØ°Ù‡Ø§ "Ø£Ø¨ÙˆÙ„Ùˆ" Ù„Ø¥Ù†ØªØ§Ø¬ Ø£Ø¹Ù…Ø§Ù„ Ø¥Ø¨Ø¯Ø§Ø¹ÙŠØ© Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ø¬ÙˆØ¯Ø©.
    """
    def __init__(self):
        self.orchestrator = apollo
        self.ingestion_engine = ingestion_engine
        self.context_engine = AdvancedContextEngine()
        self.active_pipelines: Dict[str, Dict[str, Any]] = {}

    async def run_deep_analysis_pipeline(
        self,
        project_id: str,
        source_text: str
    ) -> Dict[str, Any]:
        """
        Ø®Ø· Ø¥Ù†ØªØ§Ø¬ Ù…ØªØ®ØµØµ Ù„Ø¥Ø¬Ø±Ø§Ø¡ ØªØ­Ù„ÙŠÙ„ Ø¹Ù…ÙŠÙ‚ ÙˆØ´Ø§Ù…Ù„ Ù„Ø£ÙŠ Ù†Øµ.
        """
        pipeline_id = f"analysis_pipeline_{project_id}"
        logger.info(f"ğŸš€ [{pipeline_id}] Starting 'Deep Analysis' Pipeline...")
        self.active_pipelines[pipeline_id] = {"status": "running", "steps": {}}

        try:
            # Ø§Ù„Ø®Ø·ÙˆØ© 1: Ø¨Ù†Ø§Ø¡ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
            logger.info(f"[{pipeline_id}] STEP 1: Building initial Knowledge Base...")
            kb = await self.context_engine.analyze_text(source_text)
            self.active_pipelines[pipeline_id]["steps"]["knowledge_base"] = kb.dict()

            # Ø§Ù„Ø®Ø·ÙˆØ© 2: ØªØ´ØºÙŠÙ„ Ù…Ù‡Ø§Ù… Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØªØ®ØµØµØ© Ø¨Ø§Ù„ØªÙˆØ§Ø²ÙŠ
            logger.info(f"[{pipeline_id}] STEP 2: Running specialized analysis tasks...")
            analysis_tasks = {
                "psychological_analysis": self.orchestrator.run_task(
                    "analyze_psychological_profile", {"character_description": source_text}
                ),
                "social_conflict_map": self.orchestrator.run_task(
                    "map_social_conflicts", {"setting_description": source_text, "social_groups": [e.name for e in kb.entities if e.type == 'group']}
                ),
                "symbolism_analysis": self.orchestrator.run_task(
                    "interpret_dreams_and_symbols", {"text_content": source_text}
                )
            }
            
            results = await asyncio.gather(*analysis_tasks.values(), return_exceptions=True)
            analysis_results = dict(zip(analysis_tasks.keys(), results))

            self.active_pipelines[pipeline_id]["steps"]["specialized_analyses"] = analysis_results

            # Ø§Ù„Ø®Ø·ÙˆØ© 3: ØªØ¬Ù…ÙŠØ¹ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
            logger.info(f"[{pipeline_id}] STEP 3: Compiling final analysis report...")
            final_report = {
                "knowledge_base": kb.dict(),
                **analysis_results
            }

            self.active_pipelines[pipeline_id].update({"status": "completed", "final_report": final_report})
            logger.info(f"âœ… [{pipeline_id}] Deep Analysis Pipeline Completed Successfully.")
            return self.active_pipelines[pipeline_id]

        except Exception as e:
            logger.error(f"âŒ [{pipeline_id}] Pipeline failed: {e}", exc_info=True)
            self.active_pipelines[pipeline_id].update({"status": "failed", "error": str(e)})
            raise

    async def transmute_witness_to_creation(
        self,
        project_id: str, 
        source: Any, 
        input_type: InputType,
        creation_config: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Ø®Ø· Ø§Ù„Ø¥Ù†ØªØ§Ø¬ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ ÙˆØ§Ù„Ù…Ø­Ø³Ù†: ÙŠØ­ÙˆÙ„ Ø£ÙŠ "Ø´Ø§Ù‡Ø¯" (Ù…ØµØ¯Ø±) Ø¥Ù„Ù‰ Ø¹Ù…Ù„ Ø¥Ø¨Ø¯Ø§Ø¹ÙŠ
        Ø¹Ø¨Ø± Ù…Ø±Ø§Ø­Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹Ù…ÙŠÙ‚ØŒ ÙˆØ§Ù„Ø¹ØµÙ Ø§Ù„Ø°Ù‡Ù†ÙŠ Ø§Ù„ØªØ¹Ø§ÙˆÙ†ÙŠØŒ ÙˆØ§Ù„ÙƒØªØ§Ø¨Ø© Ø§Ù„Ù…Ø­Ø³Ù†Ø©.
        """
        pipeline_id = f"transmutation_pipeline_{project_id}"
        logger.info(f"ğŸš€ [{pipeline_id}] Starting Advanced 'Witness Transmutation' Pipeline...")
        self.active_pipelines[pipeline_id] = {"status": "running", "steps": {}}

        try:
            # --- Ø§Ù„Ù…Ø±Ø­Ù„Ø© 1: Ø§Ù„Ø§Ø³ØªÙŠØ¹Ø§Ø¨ ÙˆØ§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£ÙˆÙ„ÙŠ ---
            logger.info(f"[{pipeline_id}] STAGE 1: Ingestion & Initial Analysis...")
            ingestion_result = await self.ingestion_engine.ingest(source, input_type)
            if not ingestion_result.success:
                raise ValueError(f"Ingestion failed: {ingestion_result.error}")
            
            source_text = ingestion_result.text_content
            self.active_pipelines[pipeline_id]["steps"]["ingestion"] = {"text_length": len(source_text), "metadata": ingestion_result.metadata}

            # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø®Ø· Ø§Ù„Ø¥Ù†ØªØ§Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„ÙŠ Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù‚Ø§Ø¹Ø¯Ø© Ù…Ø¹Ø±ÙØ© Ù…Ø¹Ø²Ø²Ø©
            analysis_report = await self.run_deep_analysis_pipeline(f"{project_id}_analysis", source_text)
            enriched_kb = analysis_report.get("final_report", {})
            self.active_pipelines[pipeline_id]["steps"]["deep_analysis"] = enriched_kb

            # --- Ø§Ù„Ù…Ø±Ø­Ù„Ø© 2: Ø§Ù„ØªÙÙƒÙŠØ± ÙˆØ§Ù„Ø¥Ø¨Ø¯Ø§Ø¹ Ø§Ù„ØªØ¹Ø§ÙˆÙ†ÙŠ ---
            logger.info(f"[{pipeline_id}] STAGE 2: Collaborative Ideation...")
            
            # Ù…Ù„Ø§Ø­Ø¸Ø©: ÙŠØªØ·Ù„Ø¨ ØªÙ‡ÙŠØ¦Ø© Ø¬Ù„Ø³Ø© ØªØ¹Ø§ÙˆÙ†ÙŠØ© Ø£ÙˆÙ„Ø§Ù‹
            # collaboration_session = self.orchestrator.collaboration_system.create_collaboration_session(...)
            
            brainstorm_context = {
                "session_id": "temp_session_123", # ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ©
                "topic": f"Ø£ÙÙƒØ§Ø± Ø¥Ø¨Ø¯Ø§Ø¹ÙŠØ© Ù…Ø³ØªÙˆØ­Ø§Ø© Ù…Ù† Ø§Ù„Ù†Øµ Ø§Ù„Ø°ÙŠ ÙŠØ¨Ø¯Ø£ Ø¨Ù€: '{source_text[:50]}...'",
                "max_ideas_per_agent": 3
            }
            # brainstorming_result = await self.orchestrator.run_task(
            #     "collaborative_brainstorming", brainstorm_context
            # )
            # self.active_pipelines[pipeline_id]["steps"]["brainstorming"] = brainstorming_result
            logger.warning("Skipping collaborative brainstorming as it requires a live session.")
            
            # Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø°Ù„ÙƒØŒ Ø³Ù†Ø³ØªØ®Ø¯Ù… Ù…Ù‡Ù…Ø© Ø§Ù„Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ÙØ±Ø¯ÙŠ Ø§Ù„Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªØ­Ø³ÙŠÙ†
            idea_generation_result = await self.orchestrator.run_task(
                "generate_novel_idea",
                context={"genre_hint": creation_config.get("genre", "Ø¥Ø«Ø§Ø±Ø© ÙˆØºÙ…ÙˆØ¶"), "enriched_kb": enriched_kb}
            )
            self.active_pipelines[pipeline_id]["steps"]["idea_generation"] = idea_generation_result
            
            # --- Ø§Ù„Ù…Ø±Ø­Ù„Ø© 3: Ø§Ù„ØªØ­ÙƒÙŠÙ… ÙˆØ§Ù„ØªØ®Ø·ÙŠØ· ---
            logger.info(f"[{pipeline_id}] STAGE 3: Arbitration & Blueprinting...")
            selected_idea = idea_generation_result.get("final_content")
            
            # arbitrate_context = {"content": json.dumps(selected_idea, ensure_ascii=False), "content_type": "idea"}
            # arbitration_result = await self.orchestrator.run_task("arbitrate_content_quality", arbitrate_context)
            # self.active_pipelines[pipeline_id]["steps"]["idea_arbitration"] = arbitration_result
            logger.warning("Skipping idea arbitration as it requires a live DB/LLM connection.")

            # if arbitration_result.get("overall_score", 0) < 60:
            #     raise ValueError("The generated idea did not pass the quality arbitration.")

            blueprint_result = await self.orchestrator.run_task(
                "develop_story_blueprint",
                context={"idea": selected_idea, "knowledge_base": enriched_kb}
            )
            self.active_pipelines[pipeline_id]["steps"]["story_blueprint"] = blueprint_result

            # --- Ø§Ù„Ù…Ø±Ø­Ù„Ø© 4: Ø§Ù„Ø¥Ù†ØªØ§Ø¬ Ø§Ù„Ø¥Ø¨Ø¯Ø§Ø¹ÙŠ ---
            logger.info(f"[{pipeline_id}] STAGE 4: Creative Production...")
            story_blueprint = blueprint_result.get("final_content")
            # Ù‡Ù†Ø§ ÙŠÙ…ÙƒÙ†Ù†Ø§ Ø§Ù„Ù…Ø±ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„ÙØµÙˆÙ„ ÙˆÙƒØªØ§Ø¨ØªÙ‡Ø§ØŒ Ù„ÙƒÙ†Ù†Ø§ Ø³Ù†ÙƒØªÙÙŠ Ø¨Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© Ù„Ù„Ù…Ø±Ø§Ø­Ù„
            # for chapter_outline in story_blueprint.chapters:
            #     ...

            final_product = {
                "idea": selected_idea,
                "blueprint": story_blueprint
            }

            self.active_pipelines[pipeline_id].update({"status": "completed", "final_product": final_product})
            logger.info(f"âœ… [{pipeline_id}] Advanced Transmutation Pipeline Completed Successfully.")
            return self.active_pipelines[pipeline_id]

        except Exception as e:
            logger.error(f"âŒ [{pipeline_id}] Pipeline failed: {e}", exc_info=True)
            self.active_pipelines[pipeline_id].update({"status": "failed", "error": str(e)})
            raise

# --- Ù‚Ø³Ù… Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± ---
async def main_test():
    logger.info("\n" + "="*80)
    logger.info("ğŸ”§ WorkflowManager - Advanced Pipeline Test ğŸ”§")
    logger.info("="*80)
    
    manager = WorkflowManager()
    
    # Ù…Ø«Ø§Ù„ Ù„Ù†Øµ Ø®Ø§Ù…
    sample_text = "ÙÙŠ Ù‚Ø±ÙŠØ© ØµØºÙŠØ±Ø© ØªÙ‚Ø¹ Ø¹Ù„Ù‰ Ø­Ø§ÙØ© Ø§Ù„ØµØ­Ø±Ø§Ø¡ØŒ ÙƒØ§Ù† Ø§Ù„Ø´ÙŠØ® Ø­ÙƒÙŠÙ… Ø±Ø¬Ù„Ø§Ù‹ ÙŠØ­ØªØ±Ù…Ù‡ Ø§Ù„Ø¬Ù…ÙŠØ¹. Ù„ÙƒÙ† Ø§Ø¨Ù†Ù‡ Ø®Ø§Ù„Ø¯ ÙƒØ§Ù† Ù…ØªÙ…Ø±Ø¯Ø§Ù‹ØŒ ÙŠØ­Ù„Ù… Ø¨Ø§Ù„Ù…Ø¯ÙŠÙ†Ø© ÙˆØ£Ø¶ÙˆØ§Ø¦Ù‡Ø§. ØµØ±Ø§Ø¹ Ø¨ÙŠÙ† Ø§Ù„ØªÙ‚Ø§Ù„ÙŠØ¯ ÙˆØ§Ù„Ø­Ø¯Ø§Ø«Ø© ÙƒØ§Ù† ÙŠÙ„ÙˆØ­ ÙÙŠ Ø§Ù„Ø£ÙÙ‚ØŒ Ø®Ø§ØµØ© Ù…Ø¹ ÙˆØµÙˆÙ„ Ø´Ø±ÙƒØ© ØªØ¹Ø¯ÙŠÙ† ØºØ§Ù…Ø¶Ø© ØªØ±ÙŠØ¯ Ø´Ø±Ø§Ø¡ Ø£Ø±Ø§Ø¶ÙŠ Ø§Ù„Ù‚Ø±ÙŠØ©."

    # Ø§Ø®ØªØ¨Ø§Ø± Ø®Ø· Ø¥Ù†ØªØ§Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹Ù…ÙŠÙ‚
    logger.info("\n--- TESTING DEEP ANALYSIS PIPELINE ---")
    try:
        analysis_pipeline_result = await manager.run_deep_analysis_pipeline(
            project_id="deep_dive_001",
            source_text=sample_text
        )
        print("âœ… Deep Analysis Pipeline Result (Summary):")
        # Ø·Ø¨Ø§Ø¹Ø© Ù…Ù„Ø®Øµ ÙÙ‚Ø· Ù„ØªØ¬Ù†Ø¨ Ø§Ù„Ø¥Ø·Ø§Ù„Ø©
        print(f"Knowledge Base Entities: {len(analysis_pipeline_result['final_report']['knowledge_base']['entities'])}")
        print(f"Psychological Analysis: {'Success' if 'content' in analysis_pipeline_result['final_report']['psychological_analysis'] else 'Failed'}")
        
    except Exception as e:
        logger.error(f"âŒ Deep analysis pipeline test failed: {e}", exc_info=True)

if __name__ == "__main__":
    asyncio.run(main_test())
