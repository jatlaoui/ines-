# core/workflow_manager.py (Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© ÙˆØ§Ù„Ù…ÙØ¹Ù‘Ù„Ø©)

import logging
import json
import asyncio
from typing import Dict, Any, List

from core.apollo_orchestrator import apollo
# Ù†ÙØªØ±Ø¶ Ø£Ù† ingestion Ùˆ context engine Ù…ÙˆØ¬ÙˆØ¯Ø§Ù† ÙÙŠ Ù…Ø¬Ù„Ø¯ engines
from engines.advanced_context_engine import AdvancedContextEngine
# Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
from agents.blueprint_architect_agent import StoryBlueprint, ChapterOutline

logging.basicConfig(level=logging.INFO, format='%(asctime)s - [%(name)s] - %(levelname)s - %(message)s')
logger = logging.getLogger("WorkflowManager")

class WorkflowManager:
    """
    ÙŠØ¯ÙŠØ± Ø®Ø·ÙˆØ· Ø§Ù„Ø¥Ù†ØªØ§Ø¬ Ø§Ù„Ø¥Ø¨Ø¯Ø§Ø¹ÙŠØ© Ø§Ù„ÙƒØ§Ù…Ù„Ø© (Pipelines) Ù…Ù† Ø§Ù„Ø¨Ø¯Ø§ÙŠØ© Ø¥Ù„Ù‰ Ø§Ù„Ù†Ù‡Ø§ÙŠØ©.
    """
    def __init__(self):
        self.orchestrator = apollo
        self.context_engine = AdvancedContextEngine()
        self.active_pipelines: Dict[str, Dict[str, Any]] = {}

    async def create_narrative_from_text(
        self,
        project_id: str,
        source_text: str,
        genre_hint: str = "Ø¯Ø±Ø§Ù…Ø§ ØªØ§Ø±ÙŠØ®ÙŠØ©",
        num_chapters: int = 3
    ) -> Dict[str, Any]:
        """
        Ø®Ø· Ø§Ù„Ø¥Ù†ØªØ§Ø¬ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ: ÙŠØ£Ø®Ø° Ù†ØµÙ‹Ø§ Ø®Ø§Ù…Ù‹Ø§ ÙˆÙŠØ­ÙˆÙ„Ù‡ Ø¥Ù„Ù‰ Ù‚ØµØ© Ù‚ØµÙŠØ±Ø© Ù…ØªÙƒØ§Ù…Ù„Ø©.
        """
        pipeline_id = f"narrative_{project_id}"
        logger.info(f"ğŸš€ [{pipeline_id}] Starting 'Text-to-Narrative' Pipeline...")
        self.active_pipelines[pipeline_id] = {"status": "running", "steps": {}}
        
        try:
            # --- Ø§Ù„Ù…Ø±Ø­Ù„Ø© 1: Ø§Ù„ÙÙ‡Ù… ÙˆØ§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹Ù…ÙŠÙ‚ ---
            logger.info(f"[{pipeline_id}] STAGE 1: Deep analysis of the source text...")
            knowledge_base = await self.context_engine.analyze_text(source_text)
            self.active_pipelines[pipeline_id]["steps"]["knowledge_base"] = knowledge_base.dict()
            logger.info(f"[{pipeline_id}] âœ… KnowledgeBase created.")

            # --- Ø§Ù„Ù…Ø±Ø­Ù„Ø© 2: Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù…Ø®Ø·Ø· Ø§Ù„Ø³Ø±Ø¯ÙŠ ---
            logger.info(f"[{pipeline_id}] STAGE 2: Developing a narrative blueprint...")
            blueprint_context = {"knowledge_base": knowledge_base.dict()}
            blueprint_result = await self.orchestrator.run_task("develop_blueprint", blueprint_context)
            if blueprint_result.get("status") != "success":
                raise RuntimeError(f"Blueprint creation failed: {blueprint_result.get('message')}")

            final_blueprint_dict = blueprint_result.get("final_content").get("blueprint")
            final_blueprint = StoryBlueprint.parse_obj(final_blueprint_dict)
            self.active_pipelines[pipeline_id]["steps"]["blueprint_creation"] = final_blueprint.dict()
            logger.info(f"[{pipeline_id}] âœ… Blueprint developed successfully.")

            # --- Ø§Ù„Ù…Ø±Ø­Ù„Ø© 3: ÙƒØªØ§Ø¨Ø© Ø§Ù„ÙØµÙˆÙ„ ---
            logger.info(f"[{pipeline_id}] STAGE 3: Composing chapters...")
            composed_chapters = []
            for i, chapter_outline_data in enumerate(final_blueprint.chapters):
                # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† chapter_outline_data Ù‡Ùˆ ÙƒØ§Ø¦Ù† ChapterOutline
                chapter_outline = ChapterOutline.parse_obj(chapter_outline_data)
                logger.info(f"  -> Composing Chapter {i+1}: '{chapter_outline.title}'")
                chapter_context = {"chapter_outline": chapter_outline}
                chapter_result = await self.orchestrator.run_task("compose_chapter", chapter_context)
                
                if chapter_result.get("status") == "success":
                    composed_chapters.append(chapter_result.get("final_content"))
            
            self.active_pipelines[pipeline_id]["steps"]["chapter_composition"] = composed_chapters
            logger.info(f"[{pipeline_id}] âœ… Chapters composed.")
            
            # --- Ø§Ù„Ù…Ø±Ø­Ù„Ø© 4: ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù†ØªØ¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ ---
            final_product = {
                "title": f"Ø±ÙˆØ§ÙŠØ© Ù…Ø³ØªÙˆØ­Ø§Ø© Ù…Ù†: {source_text[:20]}...",
                "knowledge_base_summary": {
                    "entities": len(knowledge_base.entities),
                    "relationships": len(knowledge_base.relationship_graph)
                },
                "blueprint": final_blueprint.dict(),
                "chapters": composed_chapters
            }
            
            self.active_pipelines[pipeline_id].update({"status": "completed", "final_product": final_product})
            logger.info(f"ğŸ [{pipeline_id}] Pipeline Completed Successfully!")
            return self.active_pipelines[pipeline_id]

        except Exception as e:
            logger.error(f"âŒ [{pipeline_id}] Pipeline failed: {e}", exc_info=True)
            self.active_pipelines[pipeline_id].update({"status": "failed", "error": str(e)})
            raise

# --- Ù‚Ø³Ù… Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ ---
async def main_test():
    import os
    from dotenv import load_dotenv

    load_dotenv()
    if not os.getenv("GEMINI_API_KEY"):
        print("âŒ Ø®Ø·Ø£: Ù…ØªØºÙŠØ± Ø§Ù„Ø¨ÙŠØ¦Ø© GEMINI_API_KEY ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯.")
        return

    logger.info("\n" + "="*80)
    logger.info("ğŸ”§ WorkflowManager - FULL End-to-End Test ğŸ”§")
    logger.info("="*80)
    
    manager = WorkflowManager()
    
    # Ù†Øµ ØªØ§Ø±ÙŠØ®ÙŠ Ø¹Ù† ØµØ§Ù„Ø­ Ø¨Ù† ÙŠÙˆØ³Ù ÙƒÙ…ØµØ¯Ø±
    source_text = """
    ÙƒØ§Ù† ØµØ§Ù„Ø­ Ø¨Ù† ÙŠÙˆØ³Ù Ø²Ø¹ÙŠÙ…Ø§Ù‹ ÙˆØ·Ù†ÙŠØ§Ù‹ ØªÙˆÙ†Ø³ÙŠØ§Ù‹ØŒ Ø§Ø®ØªÙ„Ù Ù…Ø¹ Ø§Ù„Ø­Ø¨ÙŠØ¨ Ø¨ÙˆØ±Ù‚ÙŠØ¨Ø© Ø­ÙˆÙ„ Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„Ø§Ø³ØªÙ‚Ù„Ø§Ù„.
    Ø¢Ù…Ù† Ø¨Ù† ÙŠÙˆØ³Ù Ø¨Ø¶Ø±ÙˆØ±Ø© Ø§Ù„ÙƒÙØ§Ø­ Ø§Ù„Ù…Ø³Ù„Ø­ ÙˆØ§Ù„Ø§Ø³ØªÙ‚Ù„Ø§Ù„ Ø§Ù„ØªØ§Ù… ÙˆØ§Ù„ÙÙˆØ±ÙŠ Ø¹Ù† ÙØ±Ù†Ø³Ø§ØŒ Ø¨ÙŠÙ†Ù…Ø§ ÙØ¶Ù„ Ø¨ÙˆØ±Ù‚ÙŠØ¨Ø© Ù†Ù‡Ø¬ Ø§Ù„Ù…Ø±Ø§Ø­Ù„ ÙˆØ§Ù„ØªÙØ§ÙˆØ¶.
    Ø£Ø¯Ù‰ Ù‡Ø°Ø§ Ø§Ù„Ø®Ù„Ø§Ù Ø¥Ù„Ù‰ Ø§Ù†Ù‚Ø³Ø§Ù… Ø­Ø§Ø¯ ÙÙŠ Ø§Ù„Ø­Ø²Ø¨ Ø§Ù„Ø¯Ø³ØªÙˆØ±ÙŠ Ø§Ù„Ø¬Ø¯ÙŠØ¯ ÙˆÙÙŠ Ø§Ù„Ø´Ø§Ø±Ø¹ Ø§Ù„ØªÙˆÙ†Ø³ÙŠ. 
    ÙÙŠ Ù…Ø¤ØªÙ…Ø± ØµÙØ§Ù‚Ø³ Ø¹Ø§Ù… 1955ØŒ ØªÙ… ØªØ¬Ø±ÙŠØ¯ Ø¨Ù† ÙŠÙˆØ³Ù Ù…Ù† Ù…Ù†Ø§ØµØ¨Ù‡. Ø´Ø¹Ø± Ø¨Ø§Ù„Ø®Ø°Ù„Ø§Ù† ÙˆØ§Ù„Ù…Ø±Ø§Ø±Ø©.
    Ù„Ø§Ø­Ù‚Ø§Ù‹ØŒ ØªÙ… Ø§ØºØªÙŠØ§Ù„Ù‡ ÙÙŠ Ø£Ù„Ù…Ø§Ù†ÙŠØ§ Ø¹Ø§Ù… 1961 ÙÙŠ Ø¸Ø±ÙˆÙ ØºØ§Ù…Ø¶Ø©ØŒ Ù…Ù…Ø§ ØªØ±Ùƒ Ø¬Ø±Ø­Ø§Ù‹ Ø¹Ù…ÙŠÙ‚Ø§Ù‹ ÙÙŠ ØªØ§Ø±ÙŠØ® ØªÙˆÙ†Ø³ Ø§Ù„Ø­Ø¯ÙŠØ«.
    """

    try:
        pipeline_result = await manager.create_narrative_from_text(
            project_id="salah_ben_youssef_story",
            source_text=source_text,
            num_chapters=2 # Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø³Ø±ÙŠØ¹
        )
        
        print("\n--- âœ… Pipeline Completed! Final Product Summary: ---")
        final_product = pipeline_result.get('final_product', {})
        
        print(f"\n**Title:** {final_product.get('title')}")
        print("\n**Generated Blueprint Summary:**")
        blueprint = final_product.get('blueprint', {})
        print(f"  - Main Conflict: {blueprint.get('main_conflict')}")
        print(f"  - Themes: {blueprint.get('themes')}")
        print(f"  - Chapters: {len(blueprint.get('chapters', []))}")
        
        print("\n**Generated Chapters:**")
        for i, chapter in enumerate(final_product.get('chapters', [])):
            print(f"  --- Chapter {i+1}: {chapter.get('title')} ---")
            print(f"  Content snippet: {chapter.get('chapter_content', '')[:100]}...")
            print(f"  Quality Score: {chapter.get('quality_score')}")

    except Exception as e:
        logger.error(f"âŒ Workflow test failed at the highest level: {e}", exc_info=True)

if __name__ == "__main__":
    asyncio.run(main_test())
